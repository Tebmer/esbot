nohup: ignoring input
06/20/2022 16:46:56 - INFO - __main__ -   initializing cuda...
06/20/2022 16:46:58 - INFO - __main__ -   Input Argument Information
06/20/2022 16:46:58 - INFO - __main__ -   config_name                   strat_seq
06/20/2022 16:46:58 - INFO - __main__ -   inputter_name                 strat_seq
06/20/2022 16:46:58 - INFO - __main__ -   seed                          0
06/20/2022 16:46:58 - INFO - __main__ -   load_checkpoint               ./DATA/strat_seq.strat_seq/2022-06-20150433.3e-05.16.2gpu/epoch-1.bin
06/20/2022 16:46:58 - INFO - __main__ -   fp16                          False
06/20/2022 16:46:58 - INFO - __main__ -   max_input_length              160
06/20/2022 16:46:58 - INFO - __main__ -   max_src_turn                  None
06/20/2022 16:46:58 - INFO - __main__ -   max_decoder_input_length      40
06/20/2022 16:46:58 - INFO - __main__ -   max_knowledge_length          None
06/20/2022 16:46:58 - INFO - __main__ -   label_num                     None
06/20/2022 16:46:58 - INFO - __main__ -   multi_knl                     False
06/20/2022 16:46:58 - INFO - __main__ -   only_encode                   False
06/20/2022 16:46:58 - INFO - __main__ -   only_generate                 False
06/20/2022 16:46:58 - INFO - __main__ -   chinese                       False
06/20/2022 16:46:58 - INFO - __main__ -   add_nlg_eval                  True
06/20/2022 16:46:58 - INFO - __main__ -   min_length                    10
06/20/2022 16:46:58 - INFO - __main__ -   max_length                    40
06/20/2022 16:46:58 - INFO - __main__ -   num_return_sequences          1
06/20/2022 16:46:58 - INFO - __main__ -   infer_batch_size              8
06/20/2022 16:46:58 - INFO - __main__ -   infer_input_file              ['./_reformat/test.txt']
06/20/2022 16:46:58 - INFO - __main__ -   golden_strategy               True
06/20/2022 16:46:58 - INFO - __main__ -   temperature                   0.7
06/20/2022 16:46:58 - INFO - __main__ -   top_k                         0
06/20/2022 16:46:58 - INFO - __main__ -   top_p                         0.9
06/20/2022 16:46:58 - INFO - __main__ -   num_beams                     1
06/20/2022 16:46:58 - INFO - __main__ -   length_penalty                1.0
06/20/2022 16:46:58 - INFO - __main__ -   repetition_penalty            1.0
06/20/2022 16:46:58 - INFO - __main__ -   no_repeat_ngram_size          0
06/20/2022 16:46:58 - INFO - __main__ -   device                        cuda
06/20/2022 16:46:58 - INFO - __main__ -   n_gpu                         1
Some weights of Model were not initialized from the model checkpoint at ./Blenderbot_small-90M and are newly initialized: ['model.decoder.layers.4.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.6.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.0.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.0.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.4.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.6.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.7.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.7.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.1.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.4.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.2.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.5.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.2.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.3.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.1.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.4.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.6.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.7.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.6.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.0.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.3.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.7.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.7.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.7.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.0.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.1.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.7.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.3.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.1.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.7.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.1.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.2.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.6.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.7.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.7.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.3.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.6.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.v_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/20/2022 16:47:01 - INFO - utils.building_utils -   loading finetuned model from ./DATA/strat_seq.strat_seq/2022-06-20150433.3e-05.16.2gpu/epoch-1.bin
06/20/2022 16:47:03 - INFO - utils.building_utils -   deploying model...
06/20/2022 16:47:03 - INFO - __main__ -   Number of parameter = 99095064
06/20/2022 16:47:03 - INFO - __main__ -   Oracle generating mode.
06/20/2022 16:47:03 - INFO - utils.eval_utils -   compute eval model loss, using eval mode, please change it back to train after calling this function
validating:   0%|          | 0/195 [00:00<?, ?it/s]validating:   1%|          | 2/195 [00:00<00:10, 18.64it/s]validating:   2%|▏         | 4/195 [00:00<00:10, 18.96it/s]validating:   3%|▎         | 6/195 [00:00<00:14, 12.79it/s]validating:   5%|▍         | 9/195 [00:00<00:12, 14.66it/s]validating:   6%|▌         | 11/195 [00:00<00:17, 10.67it/s]validating:   7%|▋         | 14/195 [00:01<00:14, 12.81it/s]validating:   9%|▊         | 17/195 [00:01<00:11, 14.93it/s]validating:  10%|█         | 20/195 [00:01<00:10, 16.42it/s]validating:  12%|█▏        | 23/195 [00:01<00:09, 17.62it/s]validating:  13%|█▎        | 26/195 [00:01<00:09, 18.48it/s]validating:  15%|█▍        | 29/195 [00:01<00:08, 19.85it/s]validating:  16%|█▋        | 32/195 [00:01<00:08, 20.34it/s]validating:  18%|█▊        | 35/195 [00:01<00:07, 21.53it/s]validating:  19%|█▉        | 38/195 [00:02<00:06, 22.87it/s]validating:  21%|██        | 41/195 [00:02<00:06, 22.40it/s]validating:  23%|██▎       | 44/195 [00:02<00:06, 21.78it/s]validating:  24%|██▍       | 47/195 [00:02<00:06, 21.45it/s]validating:  26%|██▌       | 50/195 [00:02<00:09, 14.77it/s]validating:  27%|██▋       | 53/195 [00:03<00:08, 16.32it/s]validating:  29%|██▊       | 56/195 [00:03<00:07, 17.87it/s]validating:  30%|███       | 59/195 [00:03<00:07, 19.34it/s]validating:  32%|███▏      | 62/195 [00:03<00:06, 20.13it/s]validating:  33%|███▎      | 65/195 [00:03<00:06, 20.06it/s]validating:  35%|███▍      | 68/195 [00:03<00:06, 20.68it/s]validating:  36%|███▋      | 71/195 [00:03<00:05, 21.93it/s]validating:  38%|███▊      | 74/195 [00:03<00:05, 22.60it/s]validating:  39%|███▉      | 77/195 [00:04<00:04, 23.77it/s]validating:  41%|████      | 80/195 [00:04<00:04, 24.04it/s]validating:  43%|████▎     | 83/195 [00:04<00:04, 23.05it/s]validating:  44%|████▍     | 86/195 [00:04<00:06, 15.87it/s]validating:  46%|████▌     | 89/195 [00:04<00:05, 18.13it/s]validating:  47%|████▋     | 92/195 [00:04<00:05, 20.08it/s]validating:  49%|████▊     | 95/195 [00:04<00:04, 21.04it/s]validating:  50%|█████     | 98/195 [00:05<00:04, 22.26it/s]validating:  52%|█████▏    | 101/195 [00:05<00:03, 23.58it/s]validating:  53%|█████▎    | 104/195 [00:05<00:03, 24.15it/s]validating:  55%|█████▍    | 107/195 [00:05<00:03, 24.07it/s]validating:  56%|█████▋    | 110/195 [00:05<00:03, 24.74it/s]validating:  58%|█████▊    | 113/195 [00:05<00:03, 25.37it/s]validating:  59%|█████▉    | 116/195 [00:05<00:03, 24.76it/s]validating:  61%|██████    | 119/195 [00:06<00:04, 16.26it/s]validating:  63%|██████▎   | 122/195 [00:06<00:04, 17.22it/s]validating:  64%|██████▍   | 125/195 [00:06<00:05, 12.86it/s]validating:  66%|██████▌   | 128/195 [00:06<00:04, 14.88it/s]validating:  67%|██████▋   | 131/195 [00:06<00:03, 16.88it/s]validating:  69%|██████▊   | 134/195 [00:07<00:03, 19.18it/s]validating:  70%|███████   | 137/195 [00:07<00:03, 18.92it/s]validating:  72%|███████▏  | 140/195 [00:07<00:02, 20.44it/s]validating:  73%|███████▎  | 143/195 [00:07<00:02, 21.65it/s]validating:  75%|███████▍  | 146/195 [00:07<00:02, 22.19it/s]validating:  76%|███████▋  | 149/195 [00:07<00:02, 22.92it/s]validating:  78%|███████▊  | 152/195 [00:07<00:01, 23.43it/s]validating:  79%|███████▉  | 155/195 [00:07<00:01, 23.27it/s]validating:  81%|████████  | 158/195 [00:08<00:01, 24.44it/s]validating:  83%|████████▎ | 161/195 [00:08<00:02, 16.27it/s]validating:  84%|████████▍ | 164/195 [00:08<00:01, 18.35it/s]validating:  86%|████████▌ | 167/195 [00:08<00:01, 20.07it/s]validating:  87%|████████▋ | 170/195 [00:08<00:01, 14.70it/s]validating:  89%|████████▊ | 173/195 [00:09<00:01, 16.92it/s]validating:  90%|█████████ | 176/195 [00:09<00:01, 18.56it/s]validating:  92%|█████████▏| 179/195 [00:09<00:00, 19.84it/s]validating:  93%|█████████▎| 182/195 [00:09<00:00, 15.46it/s]validating:  95%|█████████▍| 185/195 [00:09<00:00, 17.34it/s]validating:  96%|█████████▋| 188/195 [00:09<00:00, 18.00it/s]validating:  98%|█████████▊| 191/195 [00:09<00:00, 19.97it/s]validating:  99%|█████████▉| 194/195 [00:10<00:00, 21.62it/s]validating: 100%|██████████| 195/195 [00:10<00:00, 19.28it/s]
inferring:   0%|          | 0/195 [00:00<?, ?it/s]inferring:   1%|          | 1/195 [00:00<01:46,  1.82it/s]inferring:   1%|          | 2/195 [00:01<02:16,  1.41it/s]inferring:   2%|▏         | 3/195 [00:02<02:36,  1.23it/s]inferring:   2%|▏         | 4/195 [00:03<02:20,  1.36it/s]inferring:   3%|▎         | 5/195 [00:04<02:39,  1.19it/s]inferring:   3%|▎         | 6/195 [00:05<03:15,  1.03s/it]inferring:   4%|▎         | 7/195 [00:06<03:06,  1.01it/s]inferring:   4%|▍         | 8/195 [00:07<03:09,  1.01s/it]inferring:   5%|▍         | 9/195 [00:08<03:04,  1.01it/s]inferring:   5%|▌         | 10/195 [00:09<03:00,  1.02it/s]inferring:   6%|▌         | 11/195 [00:11<03:30,  1.14s/it]inferring:   6%|▌         | 12/195 [00:11<02:55,  1.04it/s]inferring:   7%|▋         | 13/195 [00:12<03:00,  1.01it/s]inferring:   7%|▋         | 14/195 [00:13<02:35,  1.17it/s]inferring:   8%|▊         | 15/195 [00:14<02:45,  1.09it/s]inferring:   8%|▊         | 16/195 [00:14<02:24,  1.24it/s]inferring:   9%|▊         | 17/195 [00:15<02:19,  1.27it/s]inferring:   9%|▉         | 18/195 [00:16<02:30,  1.17it/s]inferring:  10%|▉         | 19/195 [00:17<02:35,  1.13it/s]inferring:  10%|█         | 20/195 [00:19<03:04,  1.06s/it]inferring:  11%|█         | 21/195 [00:19<02:35,  1.12it/s]inferring:  11%|█▏        | 22/195 [00:20<02:36,  1.10it/s]inferring:  12%|█▏        | 23/195 [00:22<03:04,  1.07s/it]inferring:  12%|█▏        | 24/195 [00:22<02:26,  1.17it/s]inferring:  13%|█▎        | 25/195 [00:23<02:23,  1.18it/s]inferring:  13%|█▎        | 26/195 [00:24<02:55,  1.04s/it]inferring:  14%|█▍        | 27/195 [00:25<02:29,  1.13it/s]inferring:  14%|█▍        | 28/195 [00:26<02:30,  1.11it/s]inferring:  15%|█▍        | 29/195 [00:27<02:34,  1.07it/s]inferring:  15%|█▌        | 30/195 [00:27<02:14,  1.23it/s]inferring:  16%|█▌        | 31/195 [00:29<02:50,  1.04s/it]inferring:  16%|█▋        | 32/195 [00:29<02:20,  1.16it/s]inferring:  17%|█▋        | 33/195 [00:30<02:04,  1.30it/s]inferring:  17%|█▋        | 34/195 [00:31<02:18,  1.16it/s]inferring:  18%|█▊        | 35/195 [00:32<02:25,  1.10it/s]inferring:  18%|█▊        | 36/195 [00:32<02:07,  1.25it/s]inferring:  19%|█▉        | 37/195 [00:33<01:48,  1.46it/s]inferring:  19%|█▉        | 38/195 [00:34<02:12,  1.18it/s]inferring:  20%|██        | 39/195 [00:35<02:23,  1.09it/s]inferring:  21%|██        | 40/195 [00:36<02:05,  1.23it/s]inferring:  21%|██        | 41/195 [00:37<02:40,  1.04s/it]inferring:  22%|██▏       | 42/195 [00:38<02:16,  1.12it/s]inferring:  22%|██▏       | 43/195 [00:38<01:59,  1.27it/s]inferring:  23%|██▎       | 44/195 [00:40<02:33,  1.02s/it]inferring:  23%|██▎       | 45/195 [00:40<02:10,  1.15it/s]inferring:  24%|██▎       | 46/195 [00:41<02:17,  1.08it/s]inferring:  24%|██▍       | 47/195 [00:43<02:22,  1.04it/s]inferring:  25%|██▍       | 48/195 [00:43<02:02,  1.20it/s]inferring:  25%|██▌       | 49/195 [00:44<02:06,  1.15it/s]inferring:  26%|██▌       | 50/195 [00:45<02:31,  1.05s/it]inferring:  26%|██▌       | 51/195 [00:47<02:30,  1.04s/it]inferring:  27%|██▋       | 52/195 [00:47<02:06,  1.13it/s]inferring:  27%|██▋       | 53/195 [00:48<02:13,  1.06it/s]inferring:  28%|██▊       | 54/195 [00:49<02:16,  1.03it/s]inferring:  28%|██▊       | 55/195 [00:50<01:50,  1.26it/s]inferring:  29%|██▊       | 56/195 [00:51<02:01,  1.14it/s]inferring:  29%|██▉       | 57/195 [00:51<01:43,  1.34it/s]inferring:  30%|██▉       | 58/195 [00:52<01:54,  1.20it/s]inferring:  30%|███       | 59/195 [00:53<01:55,  1.17it/s]inferring:  31%|███       | 60/195 [00:54<02:06,  1.06it/s]inferring:  31%|███▏      | 61/195 [00:55<01:49,  1.22it/s]inferring:  32%|███▏      | 62/195 [00:56<02:12,  1.01it/s]inferring:  32%|███▏      | 63/195 [00:57<01:58,  1.11it/s]inferring:  33%|███▎      | 64/195 [00:58<02:18,  1.06s/it]inferring:  33%|███▎      | 65/195 [01:00<02:32,  1.17s/it]inferring:  34%|███▍      | 66/195 [01:00<02:06,  1.02it/s]inferring:  34%|███▍      | 67/195 [01:01<02:10,  1.02s/it]inferring:  35%|███▍      | 68/195 [01:02<02:06,  1.01it/s]inferring:  35%|███▌      | 69/195 [01:03<02:06,  1.01s/it]inferring:  36%|███▌      | 70/195 [01:04<01:48,  1.15it/s]inferring:  36%|███▋      | 71/195 [01:05<01:55,  1.08it/s]inferring:  37%|███▋      | 72/195 [01:05<01:38,  1.25it/s]inferring:  37%|███▋      | 73/195 [01:07<02:04,  1.02s/it]inferring:  38%|███▊      | 74/195 [01:09<02:32,  1.26s/it]inferring:  38%|███▊      | 75/195 [01:10<02:19,  1.16s/it]inferring:  39%|███▉      | 76/195 [01:11<02:42,  1.37s/it]inferring:  39%|███▉      | 77/195 [01:12<02:24,  1.23s/it]inferring:  40%|████      | 78/195 [01:14<02:42,  1.39s/it]inferring:  41%|████      | 79/195 [01:16<02:42,  1.40s/it]inferring:  41%|████      | 80/195 [01:16<02:18,  1.21s/it]inferring:  42%|████▏     | 81/195 [01:18<02:37,  1.38s/it]inferring:  42%|████▏     | 82/195 [01:19<02:19,  1.24s/it]inferring:  43%|████▎     | 83/195 [01:21<02:36,  1.39s/it]inferring:  43%|████▎     | 84/195 [01:23<03:07,  1.69s/it]inferring:  44%|████▎     | 85/195 [01:26<03:29,  1.91s/it]inferring:  44%|████▍     | 86/195 [01:27<03:25,  1.89s/it]inferring:  45%|████▍     | 87/195 [01:29<03:16,  1.82s/it]inferring:  45%|████▌     | 88/195 [01:30<02:36,  1.46s/it]inferring:  46%|████▌     | 89/195 [01:31<02:37,  1.49s/it]inferring:  46%|████▌     | 90/195 [01:32<02:18,  1.32s/it]inferring:  47%|████▋     | 91/195 [01:33<01:59,  1.15s/it]inferring:  47%|████▋     | 92/195 [01:35<02:20,  1.37s/it]inferring:  48%|████▊     | 93/195 [01:36<02:04,  1.22s/it]inferring:  48%|████▊     | 94/195 [01:39<03:06,  1.85s/it]inferring:  49%|████▊     | 95/195 [01:40<02:36,  1.57s/it]inferring:  49%|████▉     | 96/195 [01:41<02:35,  1.57s/it]inferring:  50%|████▉     | 97/195 [01:42<02:03,  1.26s/it]inferring:  50%|█████     | 98/195 [01:44<02:11,  1.35s/it]inferring:  51%|█████     | 99/195 [01:44<01:54,  1.19s/it]inferring:  51%|█████▏    | 100/195 [01:46<02:09,  1.36s/it]inferring:  52%|█████▏    | 101/195 [01:47<01:54,  1.21s/it]inferring:  52%|█████▏    | 102/195 [01:49<02:01,  1.30s/it]inferring:  53%|█████▎    | 103/195 [01:49<01:47,  1.17s/it]inferring:  53%|█████▎    | 104/195 [01:51<02:01,  1.34s/it]inferring:  54%|█████▍    | 105/195 [01:53<02:11,  1.46s/it]inferring:  54%|█████▍    | 106/195 [01:55<02:17,  1.54s/it]inferring:  55%|█████▍    | 107/195 [01:56<02:01,  1.38s/it]inferring:  55%|█████▌    | 108/195 [01:57<02:12,  1.52s/it]inferring:  56%|█████▌    | 109/195 [01:58<01:46,  1.24s/it]inferring:  56%|█████▋    | 110/195 [01:59<01:47,  1.26s/it]inferring:  57%|█████▋    | 111/195 [02:00<01:36,  1.15s/it]inferring:  57%|█████▋    | 112/195 [02:02<01:46,  1.29s/it]inferring:  58%|█████▊    | 113/195 [02:03<01:35,  1.17s/it]inferring:  58%|█████▊    | 114/195 [02:04<01:40,  1.24s/it]inferring:  59%|█████▉    | 115/195 [02:05<01:30,  1.14s/it]inferring:  59%|█████▉    | 116/195 [02:07<01:44,  1.32s/it]inferring:  60%|██████    | 117/195 [02:09<01:53,  1.46s/it]inferring:  61%|██████    | 118/195 [02:13<03:04,  2.40s/it]inferring:  61%|██████    | 119/195 [02:15<02:49,  2.23s/it]inferring:  62%|██████▏   | 120/195 [02:17<02:38,  2.11s/it]inferring:  62%|██████▏   | 121/195 [02:19<02:29,  2.03s/it]inferring:  63%|██████▎   | 122/195 [02:21<02:36,  2.15s/it]inferring:  63%|██████▎   | 123/195 [02:26<03:25,  2.86s/it]inferring:  64%|██████▎   | 124/195 [02:27<02:41,  2.27s/it]inferring:  64%|██████▍   | 125/195 [02:28<02:24,  2.07s/it]inferring:  65%|██████▍   | 126/195 [02:30<02:18,  2.00s/it]inferring:  65%|██████▌   | 127/195 [02:32<02:07,  1.87s/it]inferring:  66%|██████▌   | 128/195 [02:33<02:02,  1.83s/it]inferring:  66%|██████▌   | 129/195 [02:34<01:39,  1.50s/it]inferring:  67%|██████▋   | 130/195 [02:35<01:36,  1.49s/it]inferring:  67%|██████▋   | 131/195 [02:37<01:38,  1.55s/it]inferring:  68%|██████▊   | 132/195 [02:38<01:24,  1.35s/it]inferring:  68%|██████▊   | 133/195 [02:39<01:15,  1.22s/it]inferring:  69%|██████▊   | 134/195 [02:40<01:05,  1.08s/it]inferring:  69%|██████▉   | 135/195 [02:42<01:29,  1.49s/it]inferring:  70%|██████▉   | 136/195 [02:44<01:42,  1.74s/it]inferring:  70%|███████   | 137/195 [02:46<01:35,  1.64s/it]inferring:  71%|███████   | 138/195 [02:47<01:21,  1.42s/it]inferring:  71%|███████▏  | 139/195 [02:49<01:26,  1.54s/it]inferring:  72%|███████▏  | 140/195 [02:50<01:28,  1.61s/it]inferring:  72%|███████▏  | 141/195 [02:52<01:29,  1.66s/it]inferring:  73%|███████▎  | 142/195 [02:53<01:15,  1.42s/it]inferring:  73%|███████▎  | 143/195 [02:54<01:14,  1.43s/it]inferring:  74%|███████▍  | 144/195 [02:56<01:18,  1.54s/it]inferring:  74%|███████▍  | 145/195 [02:57<01:08,  1.37s/it]inferring:  75%|███████▍  | 146/195 [02:59<01:13,  1.50s/it]inferring:  75%|███████▌  | 147/195 [03:00<01:08,  1.43s/it]inferring:  76%|███████▌  | 148/195 [03:01<00:52,  1.12s/it]inferring:  76%|███████▋  | 149/195 [03:02<00:48,  1.05s/it]inferring:  77%|███████▋  | 150/195 [03:02<00:44,  1.01it/s]inferring:  77%|███████▋  | 151/195 [03:04<00:52,  1.20s/it]inferring:  78%|███████▊  | 152/195 [03:05<00:44,  1.04s/it]inferring:  78%|███████▊  | 153/195 [03:07<00:53,  1.27s/it]inferring:  79%|███████▉  | 154/195 [03:08<00:55,  1.35s/it]inferring:  79%|███████▉  | 155/195 [03:09<00:49,  1.23s/it]inferring:  80%|████████  | 156/195 [03:12<01:02,  1.60s/it]inferring:  81%|████████  | 157/195 [03:12<00:52,  1.39s/it]inferring:  81%|████████  | 158/195 [03:13<00:44,  1.20s/it]inferring:  82%|████████▏ | 159/195 [03:15<00:48,  1.36s/it]inferring:  82%|████████▏ | 160/195 [03:16<00:42,  1.23s/it]inferring:  83%|████████▎ | 161/195 [03:18<00:47,  1.39s/it]inferring:  83%|████████▎ | 162/195 [03:19<00:41,  1.26s/it]inferring:  84%|████████▎ | 163/195 [03:20<00:45,  1.42s/it]inferring:  84%|████████▍ | 164/195 [03:21<00:39,  1.28s/it]inferring:  85%|████████▍ | 165/195 [03:23<00:42,  1.43s/it]inferring:  85%|████████▌ | 166/195 [03:24<00:39,  1.38s/it]inferring:  86%|████████▌ | 167/195 [03:25<00:33,  1.21s/it]inferring:  86%|████████▌ | 168/195 [03:26<00:28,  1.07s/it]inferring:  87%|████████▋ | 169/195 [03:29<00:47,  1.81s/it]inferring:  87%|████████▋ | 170/195 [03:31<00:43,  1.75s/it]inferring:  88%|████████▊ | 171/195 [03:32<00:35,  1.48s/it]inferring:  88%|████████▊ | 172/195 [03:34<00:35,  1.56s/it]inferring:  89%|████████▊ | 173/195 [03:34<00:29,  1.34s/it]inferring:  89%|████████▉ | 174/195 [03:37<00:35,  1.68s/it]inferring:  90%|████████▉ | 175/195 [03:38<00:27,  1.39s/it]inferring:  90%|█████████ | 176/195 [03:38<00:22,  1.18s/it]inferring:  91%|█████████ | 177/195 [03:40<00:24,  1.35s/it]inferring:  91%|█████████▏| 178/195 [03:41<00:20,  1.20s/it]inferring:  92%|█████████▏| 179/195 [03:43<00:21,  1.36s/it]inferring:  92%|█████████▏| 180/195 [03:45<00:22,  1.50s/it]inferring:  93%|█████████▎| 181/195 [03:45<00:18,  1.32s/it]inferring:  93%|█████████▎| 182/195 [03:48<00:22,  1.71s/it]inferring:  94%|█████████▍| 183/195 [03:49<00:17,  1.46s/it]inferring:  94%|█████████▍| 184/195 [03:50<00:15,  1.45s/it]inferring:  95%|█████████▍| 185/195 [03:51<00:11,  1.18s/it]inferring:  95%|█████████▌| 186/195 [03:53<00:13,  1.52s/it]inferring:  96%|█████████▌| 187/195 [03:55<00:12,  1.56s/it]inferring:  96%|█████████▋| 188/195 [03:57<00:11,  1.68s/it]inferring:  97%|█████████▋| 189/195 [03:58<00:08,  1.42s/it]inferring:  97%|█████████▋| 190/195 [04:00<00:07,  1.58s/it]inferring:  98%|█████████▊| 191/195 [04:00<00:05,  1.37s/it]inferring:  98%|█████████▊| 192/195 [04:02<00:04,  1.46s/it]inferring:  99%|█████████▉| 193/195 [04:03<00:02,  1.30s/it]inferring:  99%|█████████▉| 194/195 [04:05<00:01,  1.39s/it]inferring: 100%|██████████| 195/195 [04:06<00:00,  1.49s/it]inferring: 100%|██████████| 195/195 [04:06<00:00,  1.27s/it]
06/20/2022 16:51:24 - INFO - gensim.utils -   loading Word2VecKeyedVectors object from /home/xuxiaohan/wordvector/english/glove6B/glove.6B.300d.model.bin
06/20/2022 16:51:26 - INFO - gensim.utils -   loading vectors from /home/xuxiaohan/wordvector/english/glove6B/glove.6B.300d.model.bin.vectors.npy with mmap=r
06/20/2022 16:51:26 - INFO - gensim.utils -   setting ignored attribute vectors_norm to None
06/20/2022 16:51:26 - INFO - gensim.utils -   loaded /home/xuxiaohan/wordvector/english/glove6B/glove.6B.300d.model.bin
{
  "max_length": 40,
  "min_length": 10,
  "do_sample": true,
  "temperature": 0.7,
  "top_k": 0,
  "top_p": 0.9,
  "num_beams": 1,
  "num_return_sequences": 1,
  "length_penalty": 1.0,
  "repetition_penalty": 1.0,
  "no_repeat_ngram_size": 0,
  "encoder_no_repeat_ngram_size": 0,
  "pad_token_id": 0,
  "bos_token_id": 1,
  "eos_token_id": 2
}

 Epoch 0: Val loss 2.736201524734497 Val ppl 15.42827033996582 Val strategy loss 2.0826895236968994
cls_strat_id: classification_report
               precision    recall  f1-score   support

           0       0.19      0.12      0.14       566
           1       0.04      0.08      0.05       152
           2       0.08      0.11      0.09       235
           3       0.11      0.16      0.13       264
           4       0.16      0.13      0.14       434
           5       0.17      0.11      0.13       507
           6       0.05      0.10      0.07       186
           7       0.16      0.13      0.14       457

    accuracy                           0.12      2801
   macro avg       0.12      0.12      0.11      2801
weighted avg       0.14      0.12      0.13      2801

cls_strat_id: confusion_matrix
 [[66 67 68 85 71 62 78 69]
 [18 12 20 26 19 20 14 23]
 [27 28 27 23 29 24 34 43]
 [36 34 28 41 24 40 23 38]
 [52 62 48 55 56 47 61 53]
 [70 55 74 69 61 55 61 62]
 [27 17 27 26 26 22 18 23]
 [54 62 53 50 58 53 67 60]]
