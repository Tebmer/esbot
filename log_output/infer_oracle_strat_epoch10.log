nohup: ignoring input
06/20/2022 17:57:57 - INFO - __main__ -   initializing cuda...
06/20/2022 17:58:05 - INFO - __main__ -   Input Argument Information
06/20/2022 17:58:05 - INFO - __main__ -   config_name                   strat_seq
06/20/2022 17:58:05 - INFO - __main__ -   inputter_name                 strat_seq
06/20/2022 17:58:05 - INFO - __main__ -   seed                          0
06/20/2022 17:58:05 - INFO - __main__ -   load_checkpoint               ./DATA/strat_seq.strat_seq/2022-06-20171417.3e-05.16.2gpu/epoch-1.bin
06/20/2022 17:58:05 - INFO - __main__ -   fp16                          False
06/20/2022 17:58:05 - INFO - __main__ -   max_input_length              160
06/20/2022 17:58:05 - INFO - __main__ -   max_src_turn                  None
06/20/2022 17:58:05 - INFO - __main__ -   max_decoder_input_length      40
06/20/2022 17:58:05 - INFO - __main__ -   max_knowledge_length          None
06/20/2022 17:58:05 - INFO - __main__ -   label_num                     None
06/20/2022 17:58:05 - INFO - __main__ -   multi_knl                     False
06/20/2022 17:58:05 - INFO - __main__ -   only_encode                   False
06/20/2022 17:58:05 - INFO - __main__ -   only_generate                 False
06/20/2022 17:58:05 - INFO - __main__ -   chinese                       False
06/20/2022 17:58:05 - INFO - __main__ -   add_nlg_eval                  True
06/20/2022 17:58:05 - INFO - __main__ -   min_length                    10
06/20/2022 17:58:05 - INFO - __main__ -   max_length                    40
06/20/2022 17:58:05 - INFO - __main__ -   num_return_sequences          1
06/20/2022 17:58:05 - INFO - __main__ -   infer_batch_size              8
06/20/2022 17:58:05 - INFO - __main__ -   infer_input_file              ['./_reformat/test.txt']
06/20/2022 17:58:05 - INFO - __main__ -   golden_strategy               True
06/20/2022 17:58:05 - INFO - __main__ -   temperature                   0.7
06/20/2022 17:58:05 - INFO - __main__ -   top_k                         0
06/20/2022 17:58:05 - INFO - __main__ -   top_p                         0.9
06/20/2022 17:58:05 - INFO - __main__ -   num_beams                     1
06/20/2022 17:58:05 - INFO - __main__ -   length_penalty                1.0
06/20/2022 17:58:05 - INFO - __main__ -   repetition_penalty            1.0
06/20/2022 17:58:05 - INFO - __main__ -   no_repeat_ngram_size          0
06/20/2022 17:58:05 - INFO - __main__ -   device                        cuda
06/20/2022 17:58:05 - INFO - __main__ -   n_gpu                         1
Some weights of Model were not initialized from the model checkpoint at ./Blenderbot_small-90M and are newly initialized: ['model.decoder.layers.3.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.0.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.7.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.1.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.4.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.4.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.6.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.3.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.6.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.0.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.0.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.3.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.6.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.1.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.6.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.7.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.1.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.7.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.6.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.2.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.6.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.7.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.0.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.4.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.7.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.1.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.2.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.3.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.0.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.5.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.4.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.7.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.1.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.7.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.1.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.2.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.4.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.4.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.7.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.7.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.7.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.3.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.1.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.6.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.0.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.0.encoder_atten_strategy.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/20/2022 17:58:11 - INFO - utils.building_utils -   loading finetuned model from ./DATA/strat_seq.strat_seq/2022-06-20171417.3e-05.16.2gpu/epoch-1.bin
06/20/2022 17:58:20 - INFO - utils.building_utils -   deploying model...
06/20/2022 17:58:21 - INFO - __main__ -   Number of parameter = 99095064
06/20/2022 17:58:21 - INFO - __main__ -   Oracle generating mode.
06/20/2022 17:58:21 - INFO - utils.eval_utils -   compute eval model loss, using eval mode, please change it back to train after calling this function
validating:   0%|          | 0/195 [00:00<?, ?it/s]validating:   1%|          | 1/195 [00:00<00:26,  7.40it/s]validating:   2%|▏         | 3/195 [00:00<00:22,  8.56it/s]validating:   3%|▎         | 5/195 [00:00<00:21,  9.03it/s]validating:   3%|▎         | 6/195 [00:00<00:20,  9.00it/s]validating:   4%|▎         | 7/195 [00:00<00:20,  9.14it/s]validating:   5%|▍         | 9/195 [00:00<00:18,  9.98it/s]validating:   5%|▌         | 10/195 [00:00<00:18,  9.84it/s]validating:   6%|▌         | 11/195 [00:01<00:18,  9.74it/s]validating:   7%|▋         | 13/195 [00:01<00:17, 10.20it/s]validating:   8%|▊         | 15/195 [00:01<00:15, 11.31it/s]validating:   9%|▊         | 17/195 [00:01<00:15, 11.77it/s]validating:  10%|▉         | 19/195 [00:01<00:14, 11.97it/s]validating:  11%|█         | 21/195 [00:01<00:14, 11.68it/s]validating:  12%|█▏        | 23/195 [00:02<00:14, 11.57it/s]validating:  13%|█▎        | 25/195 [00:02<00:14, 11.76it/s]validating:  14%|█▍        | 27/195 [00:02<00:14, 11.94it/s]validating:  15%|█▍        | 29/195 [00:02<00:13, 12.03it/s]validating:  16%|█▌        | 31/195 [00:02<00:14, 11.61it/s]validating:  17%|█▋        | 33/195 [00:02<00:13, 12.06it/s]validating:  18%|█▊        | 35/195 [00:03<00:13, 11.65it/s]validating:  19%|█▉        | 37/195 [00:03<00:12, 12.49it/s]validating:  20%|██        | 39/195 [00:03<00:12, 12.72it/s]validating:  21%|██        | 41/195 [00:03<00:12, 12.51it/s]validating:  22%|██▏       | 43/195 [00:03<00:11, 12.70it/s]validating:  23%|██▎       | 45/195 [00:03<00:11, 12.83it/s]validating:  24%|██▍       | 47/195 [00:04<00:12, 11.86it/s]validating:  25%|██▌       | 49/195 [00:04<00:12, 11.94it/s]validating:  26%|██▌       | 51/195 [00:04<00:14, 10.12it/s]validating:  27%|██▋       | 53/195 [00:04<00:13, 10.61it/s]validating:  28%|██▊       | 55/195 [00:04<00:12, 11.63it/s]validating:  29%|██▉       | 57/195 [00:04<00:11, 12.15it/s]validating:  30%|███       | 59/195 [00:05<00:11, 12.11it/s]validating:  31%|███▏      | 61/195 [00:05<00:10, 12.51it/s]validating:  32%|███▏      | 63/195 [00:05<00:10, 12.45it/s]validating:  33%|███▎      | 65/195 [00:05<00:11, 11.02it/s]validating:  34%|███▍      | 67/195 [00:05<00:11, 11.04it/s]validating:  35%|███▌      | 69/195 [00:05<00:10, 11.52it/s]validating:  36%|███▋      | 71/195 [00:06<00:10, 11.87it/s]validating:  37%|███▋      | 73/195 [00:06<00:09, 12.50it/s]validating:  38%|███▊      | 75/195 [00:06<00:09, 12.53it/s]validating:  39%|███▉      | 77/195 [00:06<00:08, 13.13it/s]validating:  41%|████      | 79/195 [00:06<00:09, 12.70it/s]validating:  42%|████▏     | 81/195 [00:06<00:08, 13.48it/s]validating:  43%|████▎     | 83/195 [00:06<00:08, 12.72it/s]validating:  44%|████▎     | 85/195 [00:07<00:10, 10.59it/s]validating:  45%|████▍     | 87/195 [00:07<00:10, 10.57it/s]validating:  46%|████▌     | 89/195 [00:07<00:09, 11.76it/s]validating:  47%|████▋     | 91/195 [00:07<00:08, 12.49it/s]validating:  48%|████▊     | 93/195 [00:07<00:08, 12.41it/s]validating:  49%|████▊     | 95/195 [00:08<00:08, 12.16it/s]validating:  50%|████▉     | 97/195 [00:08<00:08, 11.99it/s]validating:  51%|█████     | 99/195 [00:08<00:07, 12.33it/s]validating:  52%|█████▏    | 101/195 [00:08<00:07, 12.10it/s]validating:  53%|█████▎    | 103/195 [00:08<00:07, 12.82it/s]validating:  54%|█████▍    | 105/195 [00:08<00:06, 12.88it/s]validating:  55%|█████▍    | 107/195 [00:08<00:06, 13.15it/s]validating:  56%|█████▌    | 109/195 [00:09<00:06, 13.58it/s]validating:  57%|█████▋    | 111/195 [00:09<00:05, 14.19it/s]validating:  58%|█████▊    | 113/195 [00:09<00:05, 14.28it/s]validating:  59%|█████▉    | 115/195 [00:09<00:05, 13.87it/s]validating:  60%|██████    | 117/195 [00:09<00:05, 13.39it/s]validating:  61%|██████    | 119/195 [00:09<00:07, 10.66it/s]validating:  62%|██████▏   | 121/195 [00:10<00:07, 10.29it/s]validating:  63%|██████▎   | 123/195 [00:10<00:08,  8.65it/s]validating:  64%|██████▍   | 125/195 [00:10<00:07,  9.78it/s]validating:  65%|██████▌   | 127/195 [00:10<00:06, 10.43it/s]validating:  66%|██████▌   | 129/195 [00:10<00:05, 11.13it/s]validating:  67%|██████▋   | 131/195 [00:11<00:05, 11.93it/s]validating:  68%|██████▊   | 133/195 [00:11<00:04, 12.96it/s]validating:  69%|██████▉   | 135/195 [00:11<00:04, 12.41it/s]validating:  70%|███████   | 137/195 [00:11<00:05, 11.57it/s]validating:  71%|███████▏  | 139/195 [00:11<00:04, 12.10it/s]validating:  72%|███████▏  | 141/195 [00:11<00:04, 12.54it/s]validating:  73%|███████▎  | 143/195 [00:12<00:04, 12.74it/s]validating:  74%|███████▍  | 145/195 [00:12<00:03, 12.53it/s]validating:  75%|███████▌  | 147/195 [00:12<00:03, 12.44it/s]validating:  76%|███████▋  | 149/195 [00:12<00:03, 12.42it/s]validating:  77%|███████▋  | 151/195 [00:12<00:03, 12.48it/s]validating:  78%|███████▊  | 153/195 [00:12<00:03, 12.00it/s]validating:  79%|███████▉  | 155/195 [00:13<00:03, 11.89it/s]validating:  81%|████████  | 157/195 [00:13<00:03, 11.30it/s]validating:  82%|████████▏ | 159/195 [00:13<00:02, 12.22it/s]validating:  83%|████████▎ | 161/195 [00:13<00:02, 11.81it/s]validating:  84%|████████▎ | 163/195 [00:13<00:02, 12.87it/s]validating:  85%|████████▍ | 165/195 [00:13<00:02, 13.66it/s]validating:  86%|████████▌ | 167/195 [00:13<00:02, 13.96it/s]validating:  87%|████████▋ | 169/195 [00:14<00:02, 11.59it/s]validating:  88%|████████▊ | 171/195 [00:14<00:01, 12.39it/s]validating:  89%|████████▊ | 173/195 [00:14<00:01, 12.60it/s]validating:  90%|████████▉ | 175/195 [00:14<00:01, 12.70it/s]validating:  91%|█████████ | 177/195 [00:14<00:01, 12.31it/s]validating:  92%|█████████▏| 179/195 [00:14<00:01, 12.18it/s]validating:  93%|█████████▎| 181/195 [00:15<00:01, 12.30it/s]validating:  94%|█████████▍| 183/195 [00:15<00:01, 11.28it/s]validating:  95%|█████████▍| 185/195 [00:15<00:00, 11.76it/s]validating:  96%|█████████▌| 187/195 [00:15<00:00, 12.08it/s]validating:  97%|█████████▋| 189/195 [00:15<00:00, 11.28it/s]validating:  98%|█████████▊| 191/195 [00:15<00:00, 12.18it/s]validating:  99%|█████████▉| 193/195 [00:16<00:00, 12.82it/s]validating: 100%|██████████| 195/195 [00:16<00:00, 12.39it/s]validating: 100%|██████████| 195/195 [00:16<00:00, 11.98it/s]
06/20/2022 17:58:38 - INFO - __main__ -   Perplexity: 15.446911811828613
inferring:   0%|          | 0/195 [00:00<?, ?it/s]inferring:   1%|          | 1/195 [00:00<03:03,  1.06it/s]inferring:   1%|          | 2/195 [00:01<03:03,  1.05it/s]inferring:   2%|▏         | 3/195 [00:03<03:41,  1.16s/it]inferring:   2%|▏         | 4/195 [00:04<03:09,  1.01it/s]inferring:   3%|▎         | 5/195 [00:05<03:39,  1.15s/it]inferring:   3%|▎         | 6/195 [00:07<04:22,  1.39s/it]inferring:   4%|▎         | 7/195 [00:09<04:26,  1.42s/it]inferring:   4%|▍         | 8/195 [00:10<04:47,  1.54s/it]inferring:   5%|▍         | 9/195 [00:11<04:19,  1.39s/it]inferring:   5%|▌         | 10/195 [00:13<04:07,  1.34s/it]inferring:   6%|▌         | 11/195 [00:14<04:28,  1.46s/it]inferring:   6%|▌         | 12/195 [00:15<03:53,  1.28s/it]inferring:   7%|▋         | 13/195 [00:17<04:04,  1.34s/it]inferring:   7%|▋         | 14/195 [00:18<03:36,  1.19s/it]inferring:   8%|▊         | 15/195 [00:19<03:48,  1.27s/it]inferring:   8%|▊         | 16/195 [00:20<03:06,  1.04s/it]inferring:   9%|▊         | 17/195 [00:21<03:16,  1.11s/it]inferring:   9%|▉         | 18/195 [00:22<03:08,  1.06s/it]inferring:  10%|▉         | 19/195 [00:23<03:27,  1.18s/it]inferring:  10%|█         | 20/195 [00:25<04:10,  1.43s/it]inferring:  11%|█         | 21/195 [00:26<03:33,  1.23s/it]inferring:  11%|█▏        | 22/195 [00:27<03:38,  1.26s/it]inferring:  12%|█▏        | 23/195 [00:29<03:59,  1.39s/it]inferring:  12%|█▏        | 24/195 [00:30<03:19,  1.17s/it]inferring:  13%|█▎        | 25/195 [00:31<03:28,  1.23s/it]inferring:  13%|█▎        | 26/195 [00:33<04:10,  1.48s/it]inferring:  14%|█▍        | 27/195 [00:34<03:24,  1.22s/it]inferring:  14%|█▍        | 28/195 [00:35<03:14,  1.17s/it]inferring:  15%|█▍        | 29/195 [00:36<03:27,  1.25s/it]inferring:  15%|█▌        | 30/195 [00:37<02:58,  1.08s/it]inferring:  16%|█▌        | 31/195 [00:40<04:18,  1.57s/it]inferring:  16%|█▋        | 32/195 [00:41<03:44,  1.38s/it]inferring:  17%|█▋        | 33/195 [00:42<03:21,  1.25s/it]inferring:  17%|█▋        | 34/195 [00:43<03:46,  1.41s/it]inferring:  18%|█▊        | 35/195 [00:45<04:02,  1.51s/it]inferring:  18%|█▊        | 36/195 [00:46<03:15,  1.23s/it]inferring:  19%|█▉        | 37/195 [00:46<02:46,  1.05s/it]inferring:  19%|█▉        | 38/195 [00:48<03:01,  1.16s/it]inferring:  20%|██        | 39/195 [00:49<03:14,  1.25s/it]inferring:  21%|██        | 40/195 [00:50<02:54,  1.13s/it]inferring:  21%|██        | 41/195 [00:52<03:38,  1.42s/it]inferring:  22%|██▏       | 42/195 [00:53<03:07,  1.23s/it]inferring:  22%|██▏       | 43/195 [00:54<02:51,  1.13s/it]inferring:  23%|██▎       | 44/195 [00:56<03:43,  1.48s/it]inferring:  23%|██▎       | 45/195 [00:57<03:03,  1.23s/it]inferring:  24%|██▎       | 46/195 [00:58<03:16,  1.32s/it]inferring:  24%|██▍       | 47/195 [00:59<03:02,  1.23s/it]inferring:  25%|██▍       | 48/195 [01:00<02:34,  1.05s/it]inferring:  25%|██▌       | 49/195 [01:01<02:49,  1.16s/it]inferring:  26%|██▌       | 50/195 [01:03<03:18,  1.37s/it]inferring:  26%|██▌       | 51/195 [01:05<03:31,  1.47s/it]inferring:  27%|██▋       | 52/195 [01:06<03:06,  1.30s/it]inferring:  27%|██▋       | 53/195 [01:07<03:04,  1.30s/it]inferring:  28%|██▊       | 54/195 [01:09<03:17,  1.40s/it]inferring:  28%|██▊       | 55/195 [01:09<02:41,  1.15s/it]inferring:  29%|██▊       | 56/195 [01:11<02:54,  1.26s/it]inferring:  29%|██▉       | 57/195 [01:11<02:28,  1.08s/it]inferring:  30%|██▉       | 58/195 [01:13<02:43,  1.19s/it]inferring:  30%|███       | 59/195 [01:14<02:34,  1.14s/it]inferring:  31%|███       | 60/195 [01:15<02:29,  1.11s/it]inferring:  31%|███▏      | 61/195 [01:15<01:57,  1.14it/s]inferring:  32%|███▏      | 62/195 [01:16<02:08,  1.03it/s]inferring:  32%|███▏      | 63/195 [01:18<02:16,  1.04s/it]inferring:  33%|███▎      | 64/195 [01:19<02:39,  1.22s/it]inferring:  33%|███▎      | 65/195 [01:21<02:49,  1.31s/it]inferring:  34%|███▍      | 66/195 [01:21<02:23,  1.11s/it]inferring:  34%|███▍      | 67/195 [01:23<02:48,  1.32s/it]inferring:  35%|███▍      | 68/195 [01:24<02:39,  1.26s/it]inferring:  35%|███▌      | 69/195 [01:26<02:41,  1.28s/it]inferring:  36%|███▌      | 70/195 [01:27<02:25,  1.16s/it]inferring:  36%|███▋      | 71/195 [01:28<02:33,  1.24s/it]inferring:  37%|███▋      | 72/195 [01:29<02:09,  1.06s/it]inferring:  37%|███▋      | 73/195 [01:30<02:26,  1.20s/it]inferring:  38%|███▊      | 74/195 [01:32<02:44,  1.36s/it]inferring:  38%|███▊      | 75/195 [01:33<02:27,  1.23s/it]inferring:  39%|███▉      | 76/195 [01:34<02:33,  1.29s/it]inferring:  39%|███▉      | 77/195 [01:35<02:10,  1.10s/it]inferring:  40%|████      | 78/195 [01:36<02:16,  1.16s/it]inferring:  41%|████      | 79/195 [01:38<02:21,  1.22s/it]inferring:  41%|████      | 80/195 [01:38<01:59,  1.04s/it]inferring:  42%|████▏     | 81/195 [01:40<02:17,  1.21s/it]inferring:  42%|████▏     | 82/195 [01:41<02:03,  1.09s/it]inferring:  43%|████▎     | 83/195 [01:42<02:18,  1.23s/it]inferring:  43%|████▎     | 84/195 [01:44<02:49,  1.53s/it]inferring:  44%|████▎     | 85/195 [01:46<02:47,  1.52s/it]inferring:  44%|████▍     | 86/195 [01:47<02:40,  1.47s/it]inferring:  45%|████▍     | 87/195 [01:48<02:25,  1.35s/it]inferring:  45%|████▌     | 88/195 [01:49<01:58,  1.11s/it]inferring:  46%|████▌     | 89/195 [01:50<01:57,  1.10s/it]inferring:  46%|████▌     | 90/195 [01:51<01:38,  1.07it/s]inferring:  47%|████▋     | 91/195 [01:51<01:30,  1.15it/s]inferring:  47%|████▋     | 92/195 [01:53<01:48,  1.05s/it]inferring:  48%|████▊     | 93/195 [01:53<01:38,  1.04it/s]inferring:  48%|████▊     | 94/195 [01:56<02:27,  1.46s/it]inferring:  49%|████▊     | 95/195 [01:57<02:06,  1.27s/it]inferring:  49%|████▉     | 96/195 [01:58<02:06,  1.27s/it]inferring:  50%|████▉     | 97/195 [01:59<01:46,  1.09s/it]inferring:  50%|█████     | 98/195 [02:00<01:55,  1.19s/it]inferring:  51%|█████     | 99/195 [02:01<01:42,  1.07s/it]inferring:  51%|█████▏    | 100/195 [02:03<01:59,  1.26s/it]inferring:  52%|█████▏    | 101/195 [02:03<01:42,  1.09s/it]inferring:  52%|█████▏    | 102/195 [02:05<01:48,  1.17s/it]inferring:  53%|█████▎    | 103/195 [02:05<01:30,  1.02it/s]inferring:  53%|█████▎    | 104/195 [02:07<01:35,  1.05s/it]inferring:  54%|█████▍    | 105/195 [02:08<01:45,  1.17s/it]inferring:  54%|█████▍    | 106/195 [02:09<01:46,  1.20s/it]inferring:  55%|█████▍    | 107/195 [02:10<01:26,  1.02it/s]inferring:  55%|█████▌    | 108/195 [02:11<01:43,  1.19s/it]inferring:  56%|█████▌    | 109/195 [02:12<01:33,  1.09s/it]inferring:  56%|█████▋    | 110/195 [02:13<01:33,  1.10s/it]inferring:  57%|█████▋    | 111/195 [02:14<01:22,  1.02it/s]inferring:  57%|█████▋    | 112/195 [02:16<01:35,  1.15s/it]inferring:  58%|█████▊    | 113/195 [02:16<01:19,  1.03it/s]inferring:  58%|█████▊    | 114/195 [02:18<01:28,  1.10s/it]inferring:  59%|█████▉    | 115/195 [02:18<01:22,  1.03s/it]inferring:  59%|█████▉    | 116/195 [02:20<01:21,  1.03s/it]inferring:  60%|██████    | 117/195 [02:21<01:23,  1.07s/it]inferring:  61%|██████    | 118/195 [02:24<02:11,  1.71s/it]inferring:  61%|██████    | 119/195 [02:25<02:06,  1.66s/it]inferring:  62%|██████▏   | 120/195 [02:27<01:52,  1.50s/it]inferring:  62%|██████▏   | 121/195 [02:28<01:48,  1.47s/it]inferring:  63%|██████▎   | 122/195 [02:30<02:02,  1.67s/it]inferring:  63%|██████▎   | 123/195 [02:34<02:39,  2.22s/it]inferring:  64%|██████▎   | 124/195 [02:34<02:02,  1.72s/it]inferring:  64%|██████▍   | 125/195 [02:36<02:01,  1.73s/it]inferring:  65%|██████▍   | 126/195 [02:37<01:48,  1.58s/it]inferring:  65%|██████▌   | 127/195 [02:38<01:39,  1.46s/it]inferring:  66%|██████▌   | 128/195 [02:40<01:32,  1.39s/it]inferring:  66%|██████▌   | 129/195 [02:40<01:17,  1.17s/it]inferring:  67%|██████▋   | 130/195 [02:41<01:15,  1.16s/it]inferring:  67%|██████▋   | 131/195 [02:43<01:14,  1.16s/it]inferring:  68%|██████▊   | 132/195 [02:43<01:01,  1.02it/s]inferring:  68%|██████▊   | 133/195 [02:44<00:59,  1.04it/s]inferring:  69%|██████▊   | 134/195 [02:45<00:55,  1.10it/s]inferring:  69%|██████▉   | 135/195 [02:47<01:13,  1.23s/it]inferring:  70%|██████▉   | 136/195 [02:49<01:28,  1.50s/it]inferring:  70%|███████   | 137/195 [02:50<01:20,  1.39s/it]inferring:  71%|███████   | 138/195 [02:50<01:03,  1.11s/it]inferring:  71%|███████▏  | 139/195 [02:52<01:04,  1.15s/it]inferring:  72%|███████▏  | 140/195 [02:53<00:59,  1.09s/it]inferring:  72%|███████▏  | 141/195 [02:54<00:59,  1.11s/it]inferring:  73%|███████▎  | 142/195 [02:55<00:54,  1.04s/it]inferring:  73%|███████▎  | 143/195 [02:56<00:55,  1.06s/it]inferring:  74%|███████▍  | 144/195 [02:57<01:00,  1.18s/it]inferring:  74%|███████▍  | 145/195 [02:58<00:47,  1.04it/s]inferring:  75%|███████▍  | 146/195 [02:59<00:58,  1.19s/it]inferring:  75%|███████▌  | 147/195 [03:01<01:04,  1.34s/it]inferring:  76%|███████▌  | 148/195 [03:02<00:50,  1.07s/it]inferring:  76%|███████▋  | 149/195 [03:03<00:52,  1.14s/it]inferring:  77%|███████▋  | 150/195 [03:04<00:48,  1.07s/it]inferring:  77%|███████▋  | 151/195 [03:05<00:50,  1.15s/it]inferring:  78%|███████▊  | 152/195 [03:06<00:44,  1.03s/it]inferring:  78%|███████▊  | 153/195 [03:07<00:50,  1.20s/it]inferring:  79%|███████▉  | 154/195 [03:09<00:53,  1.31s/it]inferring:  79%|███████▉  | 155/195 [03:10<00:52,  1.32s/it]inferring:  80%|████████  | 156/195 [03:13<01:02,  1.61s/it]inferring:  81%|████████  | 157/195 [03:13<00:48,  1.28s/it]inferring:  81%|████████  | 158/195 [03:14<00:41,  1.13s/it]inferring:  82%|████████▏ | 159/195 [03:15<00:43,  1.20s/it]inferring:  82%|████████▏ | 160/195 [03:16<00:36,  1.05s/it]inferring:  83%|████████▎ | 161/195 [03:17<00:39,  1.17s/it]inferring:  83%|████████▎ | 162/195 [03:18<00:35,  1.07s/it]inferring:  84%|████████▎ | 163/195 [03:20<00:37,  1.16s/it]inferring:  84%|████████▍ | 164/195 [03:20<00:30,  1.03it/s]inferring:  85%|████████▍ | 165/195 [03:21<00:27,  1.10it/s]inferring:  85%|████████▌ | 166/195 [03:22<00:23,  1.24it/s]inferring:  86%|████████▌ | 167/195 [03:22<00:22,  1.23it/s]inferring:  86%|████████▌ | 168/195 [03:23<00:21,  1.28it/s]inferring:  87%|████████▋ | 169/195 [03:26<00:37,  1.42s/it]inferring:  87%|████████▋ | 170/195 [03:27<00:33,  1.36s/it]inferring:  88%|████████▊ | 171/195 [03:28<00:26,  1.12s/it]inferring:  88%|████████▊ | 172/195 [03:29<00:24,  1.08s/it]inferring:  89%|████████▊ | 173/195 [03:30<00:22,  1.04s/it]inferring:  89%|████████▉ | 174/195 [03:32<00:31,  1.51s/it]inferring:  90%|████████▉ | 175/195 [03:33<00:24,  1.22s/it]inferring:  90%|█████████ | 176/195 [03:33<00:19,  1.02s/it]inferring:  91%|█████████ | 177/195 [03:35<00:20,  1.13s/it]inferring:  91%|█████████▏| 178/195 [03:35<00:16,  1.01it/s]inferring:  92%|█████████▏| 179/195 [03:36<00:15,  1.01it/s]inferring:  92%|█████████▏| 180/195 [03:38<00:16,  1.07s/it]inferring:  93%|█████████▎| 181/195 [03:38<00:13,  1.03it/s]inferring:  93%|█████████▎| 182/195 [03:40<00:15,  1.20s/it]inferring:  94%|█████████▍| 183/195 [03:41<00:12,  1.00s/it]inferring:  94%|█████████▍| 184/195 [03:42<00:11,  1.04s/it]inferring:  95%|█████████▍| 185/195 [03:42<00:09,  1.07it/s]inferring:  95%|█████████▌| 186/195 [03:44<00:10,  1.21s/it]inferring:  96%|█████████▌| 187/195 [03:46<00:09,  1.24s/it]inferring:  96%|█████████▋| 188/195 [03:48<00:11,  1.60s/it]inferring:  97%|█████████▋| 189/195 [03:49<00:07,  1.27s/it]inferring:  97%|█████████▋| 190/195 [03:50<00:06,  1.28s/it]inferring:  98%|█████████▊| 191/195 [03:51<00:04,  1.17s/it]inferring:  98%|█████████▊| 192/195 [03:52<00:03,  1.30s/it]inferring:  99%|█████████▉| 193/195 [03:53<00:02,  1.10s/it]inferring:  99%|█████████▉| 194/195 [03:54<00:01,  1.19s/it]inferring: 100%|██████████| 195/195 [03:56<00:00,  1.24s/it]inferring: 100%|██████████| 195/195 [03:56<00:00,  1.21s/it]
06/20/2022 18:02:37 - INFO - gensim.utils -   loading Word2VecKeyedVectors object from /home/xuxiaohan/wordvector/english/glove6B/glove.6B.300d.model.bin
06/20/2022 18:02:39 - INFO - gensim.utils -   loading vectors from /home/xuxiaohan/wordvector/english/glove6B/glove.6B.300d.model.bin.vectors.npy with mmap=r
06/20/2022 18:02:39 - INFO - gensim.utils -   setting ignored attribute vectors_norm to None
06/20/2022 18:02:39 - INFO - gensim.utils -   loaded /home/xuxiaohan/wordvector/english/glove6B/glove.6B.300d.model.bin
{
  "max_length": 40,
  "min_length": 10,
  "do_sample": true,
  "temperature": 0.7,
  "top_k": 0,
  "top_p": 0.9,
  "num_beams": 1,
  "num_return_sequences": 1,
  "length_penalty": 1.0,
  "repetition_penalty": 1.0,
  "no_repeat_ngram_size": 0,
  "encoder_no_repeat_ngram_size": 0,
  "pad_token_id": 0,
  "bos_token_id": 1,
  "eos_token_id": 2
}

 Epoch 0: Val loss 2.7374091148376465 Val ppl 15.446911811828613 Val strategy loss 2.0827341079711914
cls_strat_id: classification_report
               precision    recall  f1-score   support

           0       0.20      0.11      0.14       566
           1       0.05      0.12      0.08       152
           2       0.09      0.13      0.11       235
           3       0.10      0.15      0.12       264
           4       0.17      0.13      0.15       434
           5       0.18      0.13      0.15       507
           6       0.07      0.13      0.09       186
           7       0.15      0.12      0.13       457

    accuracy                           0.13      2801
   macro avg       0.13      0.13      0.12      2801
weighted avg       0.15      0.13      0.13      2801

cls_strat_id: confusion_matrix
 [[64 73 67 73 67 68 69 85]
 [19 19 21 13 17 27 16 20]
 [34 33 31 26 26 26 18 41]
 [27 34 29 39 32 32 39 32]
 [57 57 54 53 57 53 54 49]
 [48 52 62 77 63 64 68 73]
 [19 19 29 24 24 24 25 22]
 [53 61 51 75 57 52 52 56]]
