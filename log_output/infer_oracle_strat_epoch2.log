nohup: ignoring input
06/20/2022 17:31:11 - INFO - __main__ -   initializing cuda...
06/20/2022 17:31:14 - INFO - __main__ -   Input Argument Information
06/20/2022 17:31:14 - INFO - __main__ -   config_name                   strat_seq
06/20/2022 17:31:14 - INFO - __main__ -   inputter_name                 strat_seq
06/20/2022 17:31:14 - INFO - __main__ -   seed                          0
06/20/2022 17:31:14 - INFO - __main__ -   load_checkpoint               ./DATA/strat_seq.strat_seq/2022-06-20170649.3e-05.16.2gpu/epoch-1.bin
06/20/2022 17:31:14 - INFO - __main__ -   fp16                          False
06/20/2022 17:31:14 - INFO - __main__ -   max_input_length              160
06/20/2022 17:31:14 - INFO - __main__ -   max_src_turn                  None
06/20/2022 17:31:14 - INFO - __main__ -   max_decoder_input_length      40
06/20/2022 17:31:14 - INFO - __main__ -   max_knowledge_length          None
06/20/2022 17:31:14 - INFO - __main__ -   label_num                     None
06/20/2022 17:31:14 - INFO - __main__ -   multi_knl                     False
06/20/2022 17:31:14 - INFO - __main__ -   only_encode                   False
06/20/2022 17:31:14 - INFO - __main__ -   only_generate                 False
06/20/2022 17:31:14 - INFO - __main__ -   chinese                       False
06/20/2022 17:31:14 - INFO - __main__ -   add_nlg_eval                  True
06/20/2022 17:31:14 - INFO - __main__ -   min_length                    10
06/20/2022 17:31:14 - INFO - __main__ -   max_length                    40
06/20/2022 17:31:14 - INFO - __main__ -   num_return_sequences          1
06/20/2022 17:31:14 - INFO - __main__ -   infer_batch_size              8
06/20/2022 17:31:14 - INFO - __main__ -   infer_input_file              ['./_reformat/test.txt']
06/20/2022 17:31:14 - INFO - __main__ -   golden_strategy               True
06/20/2022 17:31:14 - INFO - __main__ -   temperature                   0.7
06/20/2022 17:31:14 - INFO - __main__ -   top_k                         0
06/20/2022 17:31:14 - INFO - __main__ -   top_p                         0.9
06/20/2022 17:31:14 - INFO - __main__ -   num_beams                     1
06/20/2022 17:31:14 - INFO - __main__ -   length_penalty                1.0
06/20/2022 17:31:14 - INFO - __main__ -   repetition_penalty            1.0
06/20/2022 17:31:14 - INFO - __main__ -   no_repeat_ngram_size          0
06/20/2022 17:31:14 - INFO - __main__ -   device                        cuda
06/20/2022 17:31:14 - INFO - __main__ -   n_gpu                         1
Some weights of Model were not initialized from the model checkpoint at ./Blenderbot_small-90M and are newly initialized: ['model.decoder.layers.7.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.4.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.6.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.7.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.4.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.0.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.7.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.5.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.4.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.1.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.1.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.7.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.0.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.7.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.6.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.3.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.1.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.5.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.3.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.7.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.6.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.6.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.5.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.3.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.1.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.3.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.0.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.0.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.0.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.6.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.k_proj.weight', 'model.decoder.layers.5.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.2.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.4.encoder_atten_strategy.q_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm_strategy.bias', 'model.decoder.layers.7.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.7.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.0.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.4.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.1.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.2.encoder_attn_layer_norm_strategy.weight', 'model.decoder.layers.3.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.3.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.1.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.7.encoder_atten_strategy.v_proj.bias', 'model.decoder.layers.7.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.4.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.2.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.2.encoder_atten_strategy.q_proj.weight', 'model.decoder.layers.4.encoder_atten_strategy.v_proj.weight', 'model.decoder.layers.5.encoder_atten_strategy.k_proj.bias', 'model.decoder.layers.5.encoder_atten_strategy.out_proj.weight', 'model.decoder.layers.6.encoder_atten_strategy.out_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm_strategy.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/20/2022 17:31:17 - INFO - utils.building_utils -   loading finetuned model from ./DATA/strat_seq.strat_seq/2022-06-20170649.3e-05.16.2gpu/epoch-1.bin
06/20/2022 17:31:19 - INFO - utils.building_utils -   deploying model...
06/20/2022 17:31:20 - INFO - __main__ -   Number of parameter = 99095064
06/20/2022 17:31:20 - INFO - __main__ -   Oracle generating mode.
06/20/2022 17:31:20 - INFO - utils.eval_utils -   compute eval model loss, using eval mode, please change it back to train after calling this function
validating:   0%|          | 0/195 [00:00<?, ?it/s]validating:   1%|          | 1/195 [00:00<00:22,  8.73it/s]validating:   2%|▏         | 3/195 [00:00<00:19,  9.70it/s]validating:   3%|▎         | 5/195 [00:00<00:18, 10.09it/s]validating:   3%|▎         | 6/195 [00:00<00:30,  6.20it/s]validating:   4%|▍         | 8/195 [00:00<00:26,  7.12it/s]validating:   5%|▌         | 10/195 [00:01<00:29,  6.30it/s]validating:   6%|▌         | 12/195 [00:01<00:23,  7.88it/s]validating:   8%|▊         | 15/195 [00:01<00:18,  9.79it/s]validating:   9%|▉         | 18/195 [00:01<00:15, 11.75it/s]validating:  10%|█         | 20/195 [00:01<00:13, 13.36it/s]validating:  12%|█▏        | 23/195 [00:01<00:11, 14.87it/s]validating:  13%|█▎        | 26/195 [00:02<00:10, 16.10it/s]validating:  15%|█▍        | 29/195 [00:02<00:09, 17.61it/s]validating:  16%|█▋        | 32/195 [00:02<00:08, 18.28it/s]validating:  18%|█▊        | 35/195 [00:02<00:08, 19.38it/s]validating:  19%|█▉        | 38/195 [00:02<00:07, 20.60it/s]validating:  21%|██        | 41/195 [00:02<00:07, 20.46it/s]validating:  23%|██▎       | 44/195 [00:02<00:07, 20.52it/s]validating:  24%|██▍       | 47/195 [00:03<00:08, 17.75it/s]validating:  25%|██▌       | 49/195 [00:03<00:09, 16.04it/s]validating:  26%|██▌       | 51/195 [00:03<00:14,  9.80it/s]validating:  27%|██▋       | 53/195 [00:03<00:14, 10.11it/s]validating:  28%|██▊       | 55/195 [00:04<00:12, 10.81it/s]validating:  29%|██▉       | 57/195 [00:04<00:12, 11.22it/s]validating:  30%|███       | 59/195 [00:04<00:11, 11.39it/s]validating:  31%|███▏      | 61/195 [00:04<00:11, 11.95it/s]validating:  32%|███▏      | 63/195 [00:04<00:11, 11.30it/s]validating:  33%|███▎      | 65/195 [00:04<00:11, 10.91it/s]validating:  34%|███▍      | 67/195 [00:05<00:11, 10.96it/s]validating:  35%|███▌      | 69/195 [00:05<00:10, 11.49it/s]validating:  36%|███▋      | 71/195 [00:05<00:10, 12.13it/s]validating:  37%|███▋      | 73/195 [00:05<00:10, 11.93it/s]validating:  38%|███▊      | 75/195 [00:05<00:09, 12.62it/s]validating:  39%|███▉      | 77/195 [00:05<00:09, 12.64it/s]validating:  41%|████      | 79/195 [00:06<00:09, 12.21it/s]validating:  42%|████▏     | 81/195 [00:06<00:09, 12.47it/s]validating:  43%|████▎     | 83/195 [00:06<00:09, 11.95it/s]validating:  44%|████▎     | 85/195 [00:06<00:14,  7.79it/s]validating:  45%|████▍     | 87/195 [00:07<00:12,  8.60it/s]validating:  46%|████▌     | 89/195 [00:07<00:11,  9.54it/s]validating:  47%|████▋     | 91/195 [00:07<00:09, 10.81it/s]validating:  48%|████▊     | 93/195 [00:07<00:08, 11.34it/s]validating:  49%|████▊     | 95/195 [00:07<00:08, 11.73it/s]validating:  50%|████▉     | 97/195 [00:07<00:07, 12.47it/s]validating:  51%|█████     | 99/195 [00:07<00:07, 12.73it/s]validating:  52%|█████▏    | 101/195 [00:08<00:07, 13.07it/s]validating:  53%|█████▎    | 103/195 [00:08<00:07, 12.72it/s]validating:  54%|█████▍    | 105/195 [00:08<00:07, 12.80it/s]validating:  55%|█████▍    | 107/195 [00:08<00:07, 12.44it/s]validating:  56%|█████▌    | 109/195 [00:08<00:06, 12.98it/s]validating:  57%|█████▋    | 111/195 [00:08<00:06, 13.58it/s]validating:  58%|█████▊    | 113/195 [00:08<00:05, 13.86it/s]validating:  59%|█████▉    | 115/195 [00:09<00:05, 13.41it/s]validating:  60%|██████    | 117/195 [00:09<00:06, 12.84it/s]validating:  61%|██████    | 119/195 [00:09<00:09,  8.09it/s]validating:  62%|██████▏   | 121/195 [00:09<00:08,  8.76it/s]validating:  63%|██████▎   | 123/195 [00:10<00:10,  6.90it/s]validating:  64%|██████▍   | 125/195 [00:10<00:08,  8.18it/s]validating:  65%|██████▌   | 127/195 [00:10<00:07,  9.32it/s]validating:  66%|██████▌   | 129/195 [00:10<00:06,  9.91it/s]validating:  67%|██████▋   | 131/195 [00:10<00:05, 10.91it/s]validating:  68%|██████▊   | 133/195 [00:11<00:05, 11.79it/s]validating:  69%|██████▉   | 135/195 [00:11<00:05, 10.97it/s]validating:  70%|███████   | 137/195 [00:11<00:05, 10.41it/s]validating:  71%|███████▏  | 139/195 [00:11<00:05, 11.01it/s]validating:  72%|███████▏  | 141/195 [00:11<00:04, 11.14it/s]validating:  73%|███████▎  | 143/195 [00:12<00:04, 11.86it/s]validating:  74%|███████▍  | 145/195 [00:12<00:03, 12.58it/s]validating:  75%|███████▌  | 147/195 [00:12<00:03, 12.07it/s]validating:  76%|███████▋  | 149/195 [00:12<00:03, 12.53it/s]validating:  77%|███████▋  | 151/195 [00:12<00:03, 12.54it/s]validating:  78%|███████▊  | 153/195 [00:12<00:03, 12.46it/s]validating:  79%|███████▉  | 155/195 [00:12<00:03, 11.96it/s]validating:  81%|████████  | 157/195 [00:13<00:03, 11.42it/s]validating:  82%|████████▏ | 159/195 [00:13<00:03,  9.45it/s]validating:  83%|████████▎ | 161/195 [00:13<00:03, 10.35it/s]validating:  84%|████████▎ | 163/195 [00:13<00:02, 11.28it/s]validating:  85%|████████▍ | 165/195 [00:13<00:02, 11.54it/s]validating:  86%|████████▌ | 167/195 [00:14<00:02, 11.96it/s]validating:  87%|████████▋ | 169/195 [00:14<00:03,  8.52it/s]validating:  88%|████████▊ | 171/195 [00:14<00:02,  9.43it/s]validating:  89%|████████▊ | 173/195 [00:14<00:02, 10.17it/s]validating:  90%|████████▉ | 175/195 [00:14<00:01, 10.41it/s]validating:  91%|█████████ | 177/195 [00:15<00:01, 11.31it/s]validating:  92%|█████████▏| 179/195 [00:15<00:01, 11.37it/s]validating:  93%|█████████▎| 181/195 [00:15<00:01, 12.03it/s]validating:  94%|█████████▍| 183/195 [00:15<00:01,  8.61it/s]validating:  95%|█████████▍| 185/195 [00:15<00:01,  9.32it/s]validating:  96%|█████████▌| 187/195 [00:16<00:00,  9.99it/s]validating:  97%|█████████▋| 189/195 [00:16<00:00, 10.08it/s]validating:  98%|█████████▊| 191/195 [00:16<00:00, 10.69it/s]validating:  99%|█████████▉| 193/195 [00:16<00:00, 11.37it/s]validating: 100%|██████████| 195/195 [00:16<00:00, 11.70it/s]validating: 100%|██████████| 195/195 [00:16<00:00, 11.60it/s]
06/20/2022 17:31:37 - INFO - __main__ -   Perplexity: 15.458088874816895
inferring:   0%|          | 0/195 [00:00<?, ?it/s]inferring:   1%|          | 1/195 [00:01<03:27,  1.07s/it]inferring:   1%|          | 2/195 [00:02<04:04,  1.27s/it]inferring:   2%|▏         | 3/195 [00:04<04:25,  1.38s/it]inferring:   2%|▏         | 4/195 [00:05<04:04,  1.28s/it]inferring:   3%|▎         | 5/195 [00:07<04:48,  1.52s/it]inferring:   3%|▎         | 6/195 [00:09<05:33,  1.76s/it]inferring:   4%|▎         | 7/195 [00:11<05:16,  1.68s/it]inferring:   4%|▍         | 8/195 [00:13<05:35,  1.80s/it]inferring:   5%|▍         | 9/195 [00:14<05:15,  1.70s/it]inferring:   5%|▌         | 10/195 [00:16<05:19,  1.72s/it]inferring:   6%|▌         | 11/195 [00:19<05:50,  1.91s/it]inferring:   6%|▌         | 12/195 [00:19<04:39,  1.53s/it]inferring:   7%|▋         | 13/195 [00:21<04:38,  1.53s/it]inferring:   7%|▋         | 14/195 [00:22<03:56,  1.31s/it]inferring:   8%|▊         | 15/195 [00:23<04:10,  1.39s/it]inferring:   8%|▊         | 16/195 [00:24<03:32,  1.19s/it]inferring:   9%|▊         | 17/195 [00:26<03:58,  1.34s/it]inferring:   9%|▉         | 18/195 [00:27<04:08,  1.41s/it]inferring:  10%|▉         | 19/195 [00:29<04:24,  1.50s/it]inferring:  10%|█         | 20/195 [00:31<04:47,  1.64s/it]inferring:  11%|█         | 21/195 [00:32<04:14,  1.46s/it]inferring:  11%|█▏        | 22/195 [00:33<04:12,  1.46s/it]inferring:  12%|█▏        | 23/195 [00:35<04:27,  1.55s/it]inferring:  12%|█▏        | 24/195 [00:36<03:45,  1.32s/it]inferring:  13%|█▎        | 25/195 [00:38<04:07,  1.45s/it]inferring:  13%|█▎        | 26/195 [00:40<05:08,  1.82s/it]inferring:  14%|█▍        | 27/195 [00:41<04:10,  1.49s/it]inferring:  14%|█▍        | 28/195 [00:42<04:03,  1.46s/it]inferring:  15%|█▍        | 29/195 [00:44<04:03,  1.47s/it]inferring:  15%|█▌        | 30/195 [00:45<03:22,  1.23s/it]inferring:  16%|█▌        | 31/195 [00:47<04:11,  1.53s/it]inferring:  16%|█▋        | 32/195 [00:47<03:19,  1.23s/it]inferring:  17%|█▋        | 33/195 [00:48<02:59,  1.10s/it]inferring:  17%|█▋        | 34/195 [00:50<03:28,  1.30s/it]inferring:  18%|█▊        | 35/195 [00:51<03:42,  1.39s/it]inferring:  18%|█▊        | 36/195 [00:52<03:19,  1.26s/it]inferring:  19%|█▉        | 37/195 [00:53<02:58,  1.13s/it]inferring:  19%|█▉        | 38/195 [00:54<03:01,  1.16s/it]inferring:  20%|██        | 39/195 [00:56<03:23,  1.30s/it]inferring:  21%|██        | 40/195 [00:57<03:04,  1.19s/it]inferring:  21%|██        | 41/195 [00:59<03:52,  1.51s/it]inferring:  22%|██▏       | 42/195 [01:00<03:20,  1.31s/it]inferring:  22%|██▏       | 43/195 [01:01<02:53,  1.14s/it]inferring:  23%|██▎       | 44/195 [01:03<03:49,  1.52s/it]inferring:  23%|██▎       | 45/195 [01:04<03:24,  1.36s/it]inferring:  24%|██▎       | 46/195 [01:06<03:22,  1.36s/it]inferring:  24%|██▍       | 47/195 [01:07<03:36,  1.47s/it]inferring:  25%|██▍       | 48/195 [01:08<03:10,  1.29s/it]inferring:  25%|██▌       | 49/195 [01:10<03:30,  1.44s/it]inferring:  26%|██▌       | 50/195 [01:12<04:11,  1.73s/it]inferring:  26%|██▌       | 51/195 [01:14<04:10,  1.74s/it]inferring:  27%|██▋       | 52/195 [01:15<03:28,  1.46s/it]inferring:  27%|██▋       | 53/195 [01:17<03:34,  1.51s/it]inferring:  28%|██▊       | 54/195 [01:18<03:44,  1.59s/it]inferring:  28%|██▊       | 55/195 [01:19<02:54,  1.24s/it]inferring:  29%|██▊       | 56/195 [01:21<03:12,  1.38s/it]inferring:  29%|██▉       | 57/195 [01:21<02:38,  1.15s/it]inferring:  30%|██▉       | 58/195 [01:23<02:52,  1.26s/it]inferring:  30%|███       | 59/195 [01:24<02:59,  1.32s/it]inferring:  31%|███       | 60/195 [01:26<03:12,  1.43s/it]inferring:  31%|███▏      | 61/195 [01:26<02:40,  1.20s/it]inferring:  32%|███▏      | 62/195 [01:28<03:05,  1.40s/it]inferring:  32%|███▏      | 63/195 [01:30<03:01,  1.38s/it]inferring:  33%|███▎      | 64/195 [01:31<03:07,  1.43s/it]inferring:  33%|███▎      | 65/195 [01:33<03:23,  1.56s/it]inferring:  34%|███▍      | 66/195 [01:34<02:52,  1.34s/it]inferring:  34%|███▍      | 67/195 [01:35<02:47,  1.31s/it]inferring:  35%|███▍      | 68/195 [01:37<02:55,  1.38s/it]inferring:  35%|███▌      | 69/195 [01:38<02:57,  1.41s/it]inferring:  36%|███▌      | 70/195 [01:39<02:32,  1.22s/it]inferring:  36%|███▋      | 71/195 [01:40<02:37,  1.27s/it]inferring:  37%|███▋      | 72/195 [01:41<02:22,  1.16s/it]inferring:  37%|███▋      | 73/195 [01:43<02:33,  1.26s/it]inferring:  38%|███▊      | 74/195 [01:45<02:52,  1.43s/it]inferring:  38%|███▊      | 75/195 [01:45<02:29,  1.24s/it]inferring:  39%|███▉      | 76/195 [01:47<02:44,  1.38s/it]inferring:  39%|███▉      | 77/195 [01:48<02:26,  1.24s/it]inferring:  40%|████      | 78/195 [01:49<02:27,  1.26s/it]inferring:  41%|████      | 79/195 [01:51<02:35,  1.34s/it]inferring:  41%|████      | 80/195 [01:52<02:17,  1.20s/it]inferring:  42%|████▏     | 81/195 [01:53<02:11,  1.15s/it]inferring:  42%|████▏     | 82/195 [01:53<01:52,  1.01it/s]inferring:  43%|████▎     | 83/195 [01:55<02:12,  1.18s/it]inferring:  43%|████▎     | 84/195 [01:57<02:44,  1.48s/it]inferring:  44%|████▎     | 85/195 [01:59<02:54,  1.59s/it]inferring:  44%|████▍     | 86/195 [02:00<02:45,  1.52s/it]inferring:  45%|████▍     | 87/195 [02:02<02:37,  1.46s/it]inferring:  45%|████▌     | 88/195 [02:02<02:05,  1.18s/it]inferring:  46%|████▌     | 89/195 [02:04<02:25,  1.37s/it]inferring:  46%|████▌     | 90/195 [02:04<01:53,  1.08s/it]inferring:  47%|████▋     | 91/195 [02:05<01:34,  1.10it/s]inferring:  47%|████▋     | 92/195 [02:07<02:00,  1.17s/it]inferring:  48%|████▊     | 93/195 [02:07<01:48,  1.07s/it]inferring:  48%|████▊     | 94/195 [02:10<02:39,  1.58s/it]inferring:  49%|████▊     | 95/195 [02:11<02:18,  1.38s/it]inferring:  49%|████▉     | 96/195 [02:13<02:20,  1.42s/it]inferring:  50%|████▉     | 97/195 [02:13<01:52,  1.15s/it]inferring:  50%|█████     | 98/195 [02:15<02:06,  1.31s/it]inferring:  51%|█████     | 99/195 [02:16<01:50,  1.15s/it]inferring:  51%|█████▏    | 100/195 [02:17<01:54,  1.21s/it]inferring:  52%|█████▏    | 101/195 [02:18<01:45,  1.12s/it]inferring:  52%|█████▏    | 102/195 [02:19<01:52,  1.21s/it]inferring:  53%|█████▎    | 103/195 [02:20<01:33,  1.02s/it]inferring:  53%|█████▎    | 104/195 [02:21<01:44,  1.15s/it]inferring:  54%|█████▍    | 105/195 [02:23<02:03,  1.37s/it]inferring:  54%|█████▍    | 106/195 [02:25<02:08,  1.44s/it]inferring:  55%|█████▍    | 107/195 [02:25<01:42,  1.16s/it]inferring:  55%|█████▌    | 108/195 [02:27<01:47,  1.24s/it]inferring:  56%|█████▌    | 109/195 [02:27<01:26,  1.01s/it]inferring:  56%|█████▋    | 110/195 [02:29<01:40,  1.19s/it]inferring:  57%|█████▋    | 111/195 [02:29<01:25,  1.01s/it]inferring:  57%|█████▋    | 112/195 [02:31<01:38,  1.19s/it]inferring:  58%|█████▊    | 113/195 [02:32<01:19,  1.03it/s]inferring:  58%|█████▊    | 114/195 [02:33<01:37,  1.21s/it]inferring:  59%|█████▉    | 115/195 [02:34<01:29,  1.12s/it]inferring:  59%|█████▉    | 116/195 [02:36<01:34,  1.19s/it]inferring:  60%|██████    | 117/195 [02:37<01:39,  1.27s/it]inferring:  61%|██████    | 118/195 [02:41<02:29,  1.94s/it]inferring:  61%|██████    | 119/195 [02:42<02:16,  1.79s/it]inferring:  62%|██████▏   | 120/195 [02:43<01:58,  1.58s/it]inferring:  62%|██████▏   | 121/195 [02:45<01:55,  1.56s/it]inferring:  63%|██████▎   | 122/195 [02:47<02:04,  1.70s/it]inferring:  63%|██████▎   | 123/195 [02:50<02:45,  2.30s/it]inferring:  64%|██████▎   | 124/195 [02:51<02:06,  1.78s/it]inferring:  64%|██████▍   | 125/195 [02:52<01:49,  1.56s/it]inferring:  65%|██████▍   | 126/195 [02:53<01:45,  1.52s/it]inferring:  65%|██████▌   | 127/195 [02:55<01:45,  1.55s/it]inferring:  66%|██████▌   | 128/195 [02:56<01:42,  1.53s/it]inferring:  66%|██████▌   | 129/195 [02:57<01:24,  1.28s/it]inferring:  67%|██████▋   | 130/195 [02:59<01:25,  1.31s/it]inferring:  67%|██████▋   | 131/195 [03:00<01:25,  1.33s/it]inferring:  68%|██████▊   | 132/195 [03:01<01:14,  1.18s/it]inferring:  68%|██████▊   | 133/195 [03:02<01:08,  1.10s/it]inferring:  69%|██████▊   | 134/195 [03:03<01:04,  1.05s/it]inferring:  69%|██████▉   | 135/195 [03:05<01:20,  1.35s/it]inferring:  70%|██████▉   | 136/195 [03:07<01:31,  1.54s/it]inferring:  70%|███████   | 137/195 [03:08<01:27,  1.51s/it]inferring:  71%|███████   | 138/195 [03:09<01:12,  1.27s/it]inferring:  71%|███████▏  | 139/195 [03:10<01:15,  1.35s/it]inferring:  72%|███████▏  | 140/195 [03:12<01:12,  1.33s/it]inferring:  72%|███████▏  | 141/195 [03:13<01:17,  1.44s/it]inferring:  73%|███████▎  | 142/195 [03:14<01:00,  1.15s/it]inferring:  73%|███████▎  | 143/195 [03:15<01:08,  1.31s/it]inferring:  74%|███████▍  | 144/195 [03:17<01:12,  1.42s/it]inferring:  74%|███████▍  | 145/195 [03:18<00:59,  1.19s/it]inferring:  75%|███████▍  | 146/195 [03:20<01:06,  1.36s/it]inferring:  75%|███████▌  | 147/195 [03:21<01:09,  1.45s/it]inferring:  76%|███████▌  | 148/195 [03:22<00:57,  1.21s/it]inferring:  76%|███████▋  | 149/195 [03:23<00:59,  1.29s/it]inferring:  77%|███████▋  | 150/195 [03:24<00:53,  1.18s/it]inferring:  77%|███████▋  | 151/195 [03:25<00:51,  1.18s/it]inferring:  78%|███████▊  | 152/195 [03:26<00:42,  1.01it/s]inferring:  78%|███████▊  | 153/195 [03:27<00:43,  1.04s/it]inferring:  79%|███████▉  | 154/195 [03:29<00:49,  1.22s/it]inferring:  79%|███████▉  | 155/195 [03:30<00:44,  1.12s/it]inferring:  80%|████████  | 156/195 [03:32<00:53,  1.37s/it]inferring:  81%|████████  | 157/195 [03:32<00:41,  1.09s/it]inferring:  81%|████████  | 158/195 [03:33<00:35,  1.04it/s]inferring:  82%|████████▏ | 159/195 [03:34<00:37,  1.03s/it]inferring:  82%|████████▏ | 160/195 [03:34<00:30,  1.14it/s]inferring:  83%|████████▎ | 161/195 [03:36<00:35,  1.05s/it]inferring:  83%|████████▎ | 162/195 [03:37<00:33,  1.02s/it]inferring:  84%|████████▎ | 163/195 [03:38<00:38,  1.21s/it]inferring:  84%|████████▍ | 164/195 [03:39<00:33,  1.10s/it]inferring:  85%|████████▍ | 165/195 [03:41<00:35,  1.19s/it]inferring:  85%|████████▌ | 166/195 [03:42<00:32,  1.12s/it]inferring:  86%|████████▌ | 167/195 [03:42<00:27,  1.03it/s]inferring:  86%|████████▌ | 168/195 [03:43<00:22,  1.19it/s]inferring:  87%|████████▋ | 169/195 [03:46<00:41,  1.59s/it]inferring:  87%|████████▋ | 170/195 [03:47<00:35,  1.42s/it]inferring:  88%|████████▊ | 171/195 [03:48<00:28,  1.20s/it]inferring:  88%|████████▊ | 172/195 [03:49<00:27,  1.19s/it]inferring:  89%|████████▊ | 173/195 [03:50<00:24,  1.10s/it]inferring:  89%|████████▉ | 174/195 [03:53<00:32,  1.54s/it]inferring:  90%|████████▉ | 175/195 [03:53<00:27,  1.35s/it]inferring:  90%|█████████ | 176/195 [03:54<00:21,  1.14s/it]inferring:  91%|█████████ | 177/195 [03:56<00:23,  1.31s/it]inferring:  91%|█████████▏| 178/195 [03:56<00:18,  1.08s/it]inferring:  92%|█████████▏| 179/195 [03:57<00:17,  1.09s/it]inferring:  92%|█████████▏| 180/195 [03:58<00:15,  1.01s/it]inferring:  93%|█████████▎| 181/195 [03:59<00:11,  1.20it/s]inferring:  93%|█████████▎| 182/195 [04:01<00:15,  1.21s/it]inferring:  94%|█████████▍| 183/195 [04:01<00:11,  1.01it/s]inferring:  94%|█████████▍| 184/195 [04:03<00:12,  1.18s/it]inferring:  95%|█████████▍| 185/195 [04:04<00:11,  1.10s/it]inferring:  95%|█████████▌| 186/195 [04:06<00:11,  1.29s/it]inferring:  96%|█████████▌| 187/195 [04:07<00:10,  1.31s/it]inferring:  96%|█████████▋| 188/195 [04:09<00:11,  1.62s/it]inferring:  97%|█████████▋| 189/195 [04:10<00:07,  1.31s/it]inferring:  97%|█████████▋| 190/195 [04:11<00:06,  1.35s/it]inferring:  98%|█████████▊| 191/195 [04:12<00:04,  1.20s/it]inferring:  98%|█████████▊| 192/195 [04:13<00:03,  1.25s/it]inferring:  99%|█████████▉| 193/195 [04:14<00:02,  1.05s/it]inferring:  99%|█████████▉| 194/195 [04:15<00:01,  1.15s/it]inferring: 100%|██████████| 195/195 [04:17<00:00,  1.29s/it]inferring: 100%|██████████| 195/195 [04:17<00:00,  1.32s/it]
06/20/2022 17:35:58 - INFO - gensim.utils -   loading Word2VecKeyedVectors object from /home/xuxiaohan/wordvector/english/glove6B/glove.6B.300d.model.bin
06/20/2022 17:36:00 - INFO - gensim.utils -   loading vectors from /home/xuxiaohan/wordvector/english/glove6B/glove.6B.300d.model.bin.vectors.npy with mmap=r
06/20/2022 17:36:00 - INFO - gensim.utils -   setting ignored attribute vectors_norm to None
06/20/2022 17:36:00 - INFO - gensim.utils -   loaded /home/xuxiaohan/wordvector/english/glove6B/glove.6B.300d.model.bin
{
  "max_length": 40,
  "min_length": 10,
  "do_sample": true,
  "temperature": 0.7,
  "top_k": 0,
  "top_p": 0.9,
  "num_beams": 1,
  "num_return_sequences": 1,
  "length_penalty": 1.0,
  "repetition_penalty": 1.0,
  "no_repeat_ngram_size": 0,
  "encoder_no_repeat_ngram_size": 0,
  "pad_token_id": 0,
  "bos_token_id": 1,
  "eos_token_id": 2
}

 Epoch 0: Val loss 2.7381324768066406 Val ppl 15.458088874816895 Val strategy loss 2.08272123336792
cls_strat_id: classification_report
               precision    recall  f1-score   support

           0       0.24      0.14      0.18       566
           1       0.05      0.11      0.06       152
           2       0.09      0.14      0.11       235
           3       0.09      0.13      0.11       264
           4       0.16      0.12      0.14       434
           5       0.17      0.10      0.13       507
           6       0.09      0.16      0.11       186
           7       0.13      0.10      0.11       457

    accuracy                           0.12      2801
   macro avg       0.13      0.13      0.12      2801
weighted avg       0.15      0.12      0.13      2801

cls_strat_id: confusion_matrix
 [[82 68 72 71 75 60 65 73]
 [16 16 20 23 16 17 19 25]
 [31 28 32 29 29 26 25 35]
 [39 43 29 34 25 30 30 34]
 [41 49 59 61 53 51 63 57]
 [60 69 63 64 62 52 69 68]
 [18 21 28 23 21 17 30 28]
 [52 59 66 68 57 57 51 47]]
